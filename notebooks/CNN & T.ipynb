{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import scipy\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from scipy import ndimage\n",
    "from keras.preprocessing.image import ImageDataGenerator, array_to_img\n",
    "import tensorflow as tf\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_folder = 'data/chest_xray/chest_xray/train'\n",
    "test_folder = 'data/chest_xray/chest_xray/val'\n",
    "val_folder = 'data/chest_xray/chest_xray/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rescale=1./255) \n",
    "batch_size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG19\n",
    "cnn_base = VGG19(weights='imagenet', \n",
    "                 include_top=False, \n",
    "                 input_shape=(244, 244, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"vgg19\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 244, 244, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 244, 244, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 244, 244, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 122, 122, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 122, 122, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 122, 122, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 61, 61, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 61, 61, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 61, 61, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 61, 61, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv4 (Conv2D)        (None, 61, 61, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 30, 30, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 30, 30, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv4 (Conv2D)        (None, 30, 30, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 15, 15, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv4 (Conv2D)        (None, 15, 15, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "=================================================================\n",
      "Total params: 20,024,384\n",
      "Trainable params: 20,024,384\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "cnn_base.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(directory, sample_amount):\n",
    "    features = np.zeros(shape=(sample_amount, 2, 2, 512)) \n",
    "    labels = np.zeros(shape=(sample_amount))\n",
    "    generator = datagen.flow_from_directory(\n",
    "        directory, target_size=(224, 224), \n",
    "        batch_size = 10, \n",
    "        class_mode='binary')\n",
    "    i=0\n",
    "    for inputs_batch, labels_batch in generator:\n",
    "        features_batch = cnn_base.predict(inputs_batch)\n",
    "        features[i * batch_size : (i + 1) * batch_size] = features_batch \n",
    "        labels[i * batch_size : (i + 1) * batch_size] = labels_batch\n",
    "        i = i + 1\n",
    "        if i * batch_size >= sample_amount:\n",
    "            break\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "WARNING:tensorflow:Model was constructed with shape (None, 244, 244, 3) for input Tensor(\"input_3:0\", shape=(None, 244, 244, 3), dtype=float32), but it was called on an input with incompatible shape (None, 224, 224, 3).\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not broadcast input array from shape (10,7,7,512) into shape (10,2,2,512)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-b3532d4c2f2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5216\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mvalidation_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m624\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextract_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_folder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrain_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m5216\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-43-fb27322fd8da>\u001b[0m in \u001b[0;36mextract_features\u001b[0;34m(directory, sample_amount)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0minputs_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_batch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mfeatures_batch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mfeatures\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfeatures_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (10,7,7,512) into shape (10,2,2,512)"
     ]
    }
   ],
   "source": [
    "train_features, train_labels = extract_features(train_folder, 5216) \n",
    "validation_features, validation_labels = extract_features(val_folder, 624) \n",
    "test_features, test_labels = extract_features(test_folder, 16)\n",
    "\n",
    "train_features = np.reshape(train_features, (5216, 2 * 2 * 512))\n",
    "validation_features = np.reshape(validation_features, (624, 2 * 2 * 512))\n",
    "test_features = np.reshape(test_features, (16, 2 * 2 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.889634601043997\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "weight_for_0 = 3875/1341\n",
    "weight_for_1 = 1\n",
    "\n",
    "class_weight = {0: (3875/1341), 1: 1}\n",
    "\n",
    "print(weight_for_0)\n",
    "print(weight_for_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.3816 - acc: 0.8917 - recall: 0.8852 - val_loss: 0.5594 - val_acc: 0.7596 - val_recall: 0.9821\n",
      "Epoch 2/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.2375 - acc: 0.9392 - recall: 0.9342 - val_loss: 0.4806 - val_acc: 0.8157 - val_recall: 0.9641\n",
      "Epoch 3/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.2047 - acc: 0.9456 - recall: 0.9419 - val_loss: 0.6784 - val_acc: 0.7532 - val_recall: 0.9846\n",
      "Epoch 4/20\n",
      "522/522 [==============================] - 3s 7ms/step - loss: 0.1901 - acc: 0.9496 - recall: 0.9458 - val_loss: 0.7133 - val_acc: 0.7516 - val_recall: 0.9846\n",
      "Epoch 5/20\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.1819 - acc: 0.9528 - recall: 0.9510 - val_loss: 0.5039 - val_acc: 0.8301 - val_recall: 0.9641\n",
      "Epoch 6/20\n",
      "522/522 [==============================] - 3s 7ms/step - loss: 0.1752 - acc: 0.9559 - recall: 0.9523 - val_loss: 0.4985 - val_acc: 0.8333 - val_recall: 0.9641\n",
      "Epoch 7/20\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.1711 - acc: 0.9567 - recall: 0.9548 - val_loss: 0.5079 - val_acc: 0.8349 - val_recall: 0.9667\n",
      "Epoch 8/20\n",
      "522/522 [==============================] - 4s 7ms/step - loss: 0.1641 - acc: 0.9572 - recall: 0.9538 - val_loss: 0.5827 - val_acc: 0.8189 - val_recall: 0.9769\n",
      "Epoch 9/20\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.1572 - acc: 0.9595 - recall: 0.9577 - val_loss: 0.4807 - val_acc: 0.8429 - val_recall: 0.9615\n",
      "Epoch 10/20\n",
      "522/522 [==============================] - 4s 8ms/step - loss: 0.1530 - acc: 0.9607 - recall: 0.9577 - val_loss: 0.9596 - val_acc: 0.7404 - val_recall: 0.9923\n",
      "Epoch 11/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1546 - acc: 0.9613 - recall: 0.9587 - val_loss: 0.6657 - val_acc: 0.7981 - val_recall: 0.9795\n",
      "Epoch 12/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1504 - acc: 0.9603 - recall: 0.9572 - val_loss: 0.6714 - val_acc: 0.8045 - val_recall: 0.9769\n",
      "Epoch 13/20\n",
      "522/522 [==============================] - 3s 6ms/step - loss: 0.1477 - acc: 0.9624 - recall: 0.9610 - val_loss: 0.8347 - val_acc: 0.7692 - val_recall: 0.9846\n",
      "Epoch 14/20\n",
      "522/522 [==============================] - 4s 7ms/step - loss: 0.1418 - acc: 0.9636 - recall: 0.9600 - val_loss: 0.6331 - val_acc: 0.8205 - val_recall: 0.9744\n",
      "Epoch 15/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1430 - acc: 0.9603 - recall: 0.9592 - val_loss: 0.6119 - val_acc: 0.8221 - val_recall: 0.9744\n",
      "Epoch 16/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1394 - acc: 0.9626 - recall: 0.9603 - val_loss: 0.7579 - val_acc: 0.7869 - val_recall: 0.9795\n",
      "Epoch 17/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1364 - acc: 0.9664 - recall: 0.9634 - val_loss: 0.5725 - val_acc: 0.8349 - val_recall: 0.9667\n",
      "Epoch 18/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1366 - acc: 0.9661 - recall: 0.9646 - val_loss: 0.7107 - val_acc: 0.8029 - val_recall: 0.9769\n",
      "Epoch 19/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1300 - acc: 0.9688 - recall: 0.9677 - val_loss: 0.6885 - val_acc: 0.8093 - val_recall: 0.9744\n",
      "Epoch 20/20\n",
      "522/522 [==============================] - 3s 5ms/step - loss: 0.1316 - acc: 0.9655 - recall: 0.9644 - val_loss: 0.7908 - val_acc: 0.7965 - val_recall: 0.9821\n"
     ]
    }
   ],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=2*2*512))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-4),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['acc', tf.keras.metrics.Recall()])\n",
    "\n",
    "history = model.fit(train_features, train_labels,\n",
    "                    epochs=20,\n",
    "                    class_weight = class_weight,\n",
    "                    batch_size=10,\n",
    "                    validation_data=(validation_features, validation_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163/163 [==============================] - 0s 2ms/step - loss: 0.0848 - acc: 0.9661 - recall: 0.9608\n",
      "20/20 [==============================] - 0s 2ms/step - loss: 0.7908 - acc: 0.7965 - recall: 0.9821\n"
     ]
    }
   ],
   "source": [
    "results_train = model.evaluate(train_features, train_labels)\n",
    "results_val = model.evaluate(validation_features, validation_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-18-86dfa126f1fa>:1: Sequential.predict_classes (from tensorflow.python.keras.engine.sequential) is deprecated and will be removed after 2021-01-01.\n",
      "Instructions for updating:\n",
      "Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n"
     ]
    }
   ],
   "source": [
    "pred_train_y = model.predict_classes(train_features)\n",
    "pred_val_y = model.predict_classes(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      0.98      0.94      1341\n",
      "         1.0       0.99      0.96      0.98      3875\n",
      "\n",
      "    accuracy                           0.97      5216\n",
      "   macro avg       0.94      0.97      0.96      5216\n",
      "weighted avg       0.97      0.97      0.97      5216\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.94      0.49      0.64       234\n",
      "         1.0       0.76      0.98      0.86       390\n",
      "\n",
      "    accuracy                           0.80       624\n",
      "   macro avg       0.85      0.73      0.75       624\n",
      "weighted avg       0.83      0.80      0.78       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(train_labels, pred_train_y))\n",
    "print(classification_report(validation_labels, pred_val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Extraction Method 2**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "model.add(cnn_base)\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(132, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Freezing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 True\n",
      "flatten True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "36\n"
     ]
    }
   ],
   "source": [
    "# You can check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "    \n",
    "# Similarly, you can check how many trainable weights are in the model\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_base.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vgg19 False\n",
      "flatten True\n",
      "dense_2 True\n",
      "dense_3 True\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# You can check whether a layer is trainable (or alter its setting) through the layer.trainable attribute\n",
    "for layer in model.layers:\n",
    "    print(layer.name, layer.trainable)\n",
    "    \n",
    "# Similarly, we can check how many trainable weights are in the model\n",
    "print(len(model.trainable_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5216 images belonging to 2 classes.\n",
      "Found 624 images belonging to 2 classes.\n",
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Get all the data in the directory split/train (542 images), and reshape them\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, \n",
    "                                   rotation_range=40, \n",
    "                                   width_shift_range=0.2, \n",
    "                                   height_shift_range=0.2, \n",
    "                                   shear_range=0.2, \n",
    "                                   zoom_range=0.2, \n",
    "                                   horizontal_flip=True, \n",
    "                                   fill_mode='nearest')\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_folder,  \n",
    "                                                    target_size=(64, 64),  \n",
    "                                                    batch_size= 20, \n",
    "                                                    class_mode= 'binary') \n",
    "\n",
    "# Get all the data in the directory split/validation (200 images), and reshape them\n",
    "val_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(val_folder,  \n",
    "                                                                       target_size=(64, 64),  \n",
    "                                                                       batch_size=20, \n",
    "                                                                       class_mode='binary')\n",
    "\n",
    "# Get all the data in the directory split/test (180 images), and reshape them\n",
    "test_generator = ImageDataGenerator(rescale=1./255).flow_from_directory(test_folder,  \n",
    "                                                                        target_size=(64, 64), \n",
    "                                                                        batch_size=180,\n",
    "                                                                        class_mode='binary')\n",
    "\n",
    "test_images, test_labels = next(test_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['acc', tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-26-7aae722806ff>:1: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "Epoch 1/10\n",
      "27/27 [==============================] - 33s 1s/step - loss: 1.0405 - acc: 0.4104 - recall_1: 0.3134 - val_loss: 0.7000 - val_acc: 0.5000 - val_recall_1: 0.2160\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 34s 1s/step - loss: 0.9894 - acc: 0.6407 - recall_1: 0.6889 - val_loss: 0.6827 - val_acc: 0.5450 - val_recall_1: 0.3206\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.9709 - acc: 0.6815 - recall_1: 0.6998 - val_loss: 0.6383 - val_acc: 0.6600 - val_recall_1: 0.4590\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.9549 - acc: 0.7704 - recall_1: 0.7881 - val_loss: 0.6578 - val_acc: 0.5900 - val_recall_1: 0.2807\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 27s 1s/step - loss: 0.9262 - acc: 0.7148 - recall_1: 0.6633 - val_loss: 0.6500 - val_acc: 0.6500 - val_recall_1: 0.4733\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.8607 - acc: 0.7722 - recall_1: 0.8238 - val_loss: 0.6136 - val_acc: 0.6950 - val_recall_1: 0.5250\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.8624 - acc: 0.7944 - recall_1: 0.8144 - val_loss: 0.5656 - val_acc: 0.7500 - val_recall_1: 0.6316\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 32s 1s/step - loss: 0.8521 - acc: 0.7685 - recall_1: 0.8088 - val_loss: 0.6154 - val_acc: 0.6800 - val_recall_1: 0.5385\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 28s 1s/step - loss: 0.8314 - acc: 0.7833 - recall_1: 0.7985 - val_loss: 0.6271 - val_acc: 0.6350 - val_recall_1: 0.4180\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 29s 1s/step - loss: 0.8271 - acc: 0.7463 - recall_1: 0.7232 - val_loss: 0.5965 - val_acc: 0.6900 - val_recall_1: 0.5606\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=27,\n",
    "                              epochs=10,\n",
    "                              class_weight = class_weight,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "261/261 [==============================] - 241s 922ms/step - loss: 0.5259 - acc: 0.8064 - recall_1: 0.8230\n",
      "32/32 [==============================] - 29s 898ms/step - loss: 0.5783 - acc: 0.7147 - recall_1: 0.5744\n"
     ]
    }
   ],
   "source": [
    "results2_train = model.evaluate(train_generator)\n",
    "results2_val = model.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epch = range(1, len(train_acc) + 1)\n",
    "plt.plot(epch, train_acc, 'g.', label='Training Accuracy')\n",
    "plt.plot(epch, val_acc, 'g', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epch, train_loss, 'r.', label='Training loss')\n",
    "plt.plot(epch, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Fine Tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn_base.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cnn_base.trainable = True\n",
    "set_trainable = False\n",
    "for layer in cnn_base.layers:\n",
    "    if layer.name == 'block5_conv1':\n",
    "        set_trainable = True\n",
    "    if set_trainable:\n",
    "        layer.trainable = True\n",
    "    else:\n",
    "        layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy', \n",
    "              optimizer=optimizers.RMSprop(lr=1e-4), \n",
    "              metrics=['accuracy', tf.keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "27/27 [==============================] - 33s 1s/step - loss: 0.8813 - accuracy: 0.7278 - recall_2: 0.7189 - val_loss: 0.4405 - val_accuracy: 0.7950 - val_recall_2: 0.9925\n",
      "Epoch 2/10\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.7307 - accuracy: 0.7741 - recall_2: 0.7430 - val_loss: 0.4673 - val_accuracy: 0.7350 - val_recall_2: 0.6328\n",
      "Epoch 3/10\n",
      "27/27 [==============================] - 37s 1s/step - loss: 0.5035 - accuracy: 0.8222 - recall_2: 0.7990 - val_loss: 0.4868 - val_accuracy: 0.8100 - val_recall_2: 0.7348\n",
      "Epoch 4/10\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.5400 - accuracy: 0.8315 - recall_2: 0.8267 - val_loss: 0.3667 - val_accuracy: 0.8300 - val_recall_2: 0.7805\n",
      "Epoch 5/10\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.6108 - accuracy: 0.8222 - recall_2: 0.8035 - val_loss: 0.3178 - val_accuracy: 0.8850 - val_recall_2: 0.9470\n",
      "Epoch 6/10\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.5079 - accuracy: 0.8519 - recall_2: 0.8329 - val_loss: 0.3341 - val_accuracy: 0.8750 - val_recall_2: 0.8516\n",
      "Epoch 7/10\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.5069 - accuracy: 0.8481 - recall_2: 0.8372 - val_loss: 0.5270 - val_accuracy: 0.6650 - val_recall_2: 0.5303\n",
      "Epoch 8/10\n",
      "27/27 [==============================] - 36s 1s/step - loss: 0.4405 - accuracy: 0.8944 - recall_2: 0.8797 - val_loss: 0.4161 - val_accuracy: 0.8050 - val_recall_2: 0.7344\n",
      "Epoch 9/10\n",
      "27/27 [==============================] - 38s 1s/step - loss: 0.5036 - accuracy: 0.8389 - recall_2: 0.8281 - val_loss: 0.5924 - val_accuracy: 0.6250 - val_recall_2: 0.4308\n",
      "Epoch 10/10\n",
      "27/27 [==============================] - 35s 1s/step - loss: 0.4373 - accuracy: 0.8667 - recall_2: 0.8444 - val_loss: 0.3437 - val_accuracy: 0.8450 - val_recall_2: 0.8160\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=27,\n",
    "                              epochs=10,\n",
    "                              class_weight = class_weight,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32/32 [==============================] - 21s 650ms/step - loss: 0.3271 - accuracy: 0.8622 - recall_2: 0.8308\n"
     ]
    }
   ],
   "source": [
    "#results3_train = model.evaluate(train_generator)\n",
    "results3_val = model.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epch = range(1, len(train_acc) + 1)\n",
    "plt.plot(epch, train_acc, 'g.', label='Training Accuracy')\n",
    "plt.plot(epch, val_acc, 'g', label='Validation acc')\n",
    "plt.title('Accuracy')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epch, train_loss, 'r.', label='Training loss')\n",
    "plt.plot(epch, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_train_y = model.predict_classes(train_features)\n",
    "pred_val_y = model.predict_classes(validation_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
